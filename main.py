from langchain import PromptTemplate
from rag.vector_store import init_vectorstore
from embeddings.jina import JinaEmbedding as Jina
import os
from models.gemini import Gemini

# INIT MODELS
embedding_model = Jina()

llm_prompt_template = PromptTemplate(
    template="""
HÃ£y trá»Ÿ thÃ nh má»™t trá»£ lÃ½ áº£o chuyÃªn nghiá»‡p cá»§a trÆ°á»ng Äáº¡i há»c SÆ° pháº¡m Ká»¹ thuáº­t TP.HCM. Báº¡n sáº½ tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a sinh viÃªn vá» trÆ°á»ng há»c chÃ­nh xÃ¡c nháº¥t. LÃ  ngÆ°á»i Ä‘áº¡i diá»‡n cá»§a trÆ°á»ng báº¡n sáº½ xÆ°ng hÃ´ lÃ  mÃ¬nh vÃ  báº¡n trong má»i trÆ°á»ng há»£p, báº¡n cáº§n tráº£ lá»i chÃ­nh xÃ¡c tá»« Ã¡c thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p.
        HÃ£y Ä‘Ã³ng vai trÃ² cá»§a mÃ¬nh vÃ  tráº£ lá»i cÃ¢u há»i sau:
        CÃ¢u há»i: {question}
        Ngá»¯ cáº£nh: {context}
        Tráº£ lá»i:
    """,
    input_variables=["question", "context"]
)

step_back_llm_prompt_template = PromptTemplate(
    template="""Báº¡n lÃ  má»™t chuyÃªn gia viáº¿t láº¡i cÃ¢u há»i tÆ° váº¥n tuyá»ƒn sinh cá»§a TrÆ°á»ng Äáº¡i Há»c SÆ° Pháº¡m Ká»¹ Thuáº­t TP. Há»“ ChÃ­ Minh (SPKT hoáº·c HCMUTE). Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  viáº¿t láº¡i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng sao cho rÃµ rÃ ng, Ä‘áº§y Ä‘á»§ vÃ  dá»… hiá»ƒu hÆ¡n, nhÆ°ng váº«n giá»¯ nguyÃªn Ã½ nghÄ©a gá»‘c. HÃ£y Ä‘áº£m báº£o cÃ¢u há»i sau khi chá»‰nh sá»­a cÃ³ Ä‘á»§ ngá»¯ cáº£nh vÃ  khÃ´ng gÃ¢y hiá»ƒu láº§m vÃ  chá»‰ Ä‘Æ°a ra cÃ¢u há»i Ä‘Ã£ viáº¿t láº¡i. HÃ£y tá»« chá»‘i viá»‡c tráº£ lá»i cÃ¡c cÃ¢u há»i vi pháº¡m phÃ¡p luáº­t hoáº·c khÃ´ng phÃ¹ há»£p vá»›i Ä‘áº¡o Ä‘á»©c. CÃ¢u há»i cáº§n chá»‰nh sá»­a: "{question}". CÃ¢u há»i Ä‘Ã£ chá»‰nh sá»­a:""",
    input_variables=["question"]
)


print(os.getenv("GEMINI_API_KEY"))
vec_db = init_vectorstore(data_path="./data/V2_DATASET.csv", db_name="hcmute-admission-v2", embed_columns=["title", "content"], embedding_model=embedding_model,rerank_top_k=8)
from classifier import CategoryClassifier
agent = Gemini(api_key=os.getenv("GEMINI_API_KEY"), llm_prompt_template=llm_prompt_template)
classifier_agent = CategoryClassifier()
step_back_agent = Gemini(api_key=os.getenv("GEMINI_API_KEY"), llm_prompt_template=step_back_llm_prompt_template, model_variant="gemini-1.5-pro")
q_a = []
print(os.getenv("JINA_API_KEY"))
def pipeline(query: str, is_logging_retrieval: bool = False, is_logging_qa: bool = False):
    # Step back to retrieve context
    rewrite_query = step_back_agent.chain.invoke({"question": query})
    print("Original query: ", query)
    query = rewrite_query
    print("Rewrite query: ", rewrite_query)
    filter_cat = classifier_agent.classify(query)
    docs = vec_db.retrieve(rewrite_query, is_logging=is_logging_retrieval, category=filter_cat)

    
    context_chunks = []
    for doc in docs:
        if doc["type"] == "question":
            context_chunks.append(f"**Chunk: {doc['title']}**\n{doc['content']})")
        else:
            context_chunks.append(f"**Chunk: {doc['title']}**\n{doc['content']}")

    context = "\n".join(context_chunks)
    # print("___________CONTEXT___________")
    # print(context)
    # print("____________________________")
    answer = agent.chain.invoke({"question":query, "context":context})
    if is_logging_qa:
        print({
            # "question": query,
            "answer": answer,
        })
        q_a.append({"question": query, "answer": answer, "context":context, "docs": docs})
    return answer

# # print(pipeline("NgÃ nh cá»§a trÆ°á»ng", is_logging_qa=True))
# print(pipeline("Nhuá»™m tÃ³c Ä‘Æ°á»£c k v?", is_logging_qa=True))
# print(pipeline("TrÆ°á»ng thÃ nh láº­p bao lÃ¢u rá»“i?", is_logging_qa=True))
# print(pipeline("CÃ³ nÃªn há»c spkt?", is_logging_qa=True))
# print(pipeline("Ai lÃ  hiá»‡u trÆ°á»Ÿng v", is_logging_qa=True))
# print(pipeline("Ai lÃ  hiá»‡u phÃ³ v", is_logging_qa=True))



# # # UI

import streamlit as st
import random
import time

def response_generator(question):
    return pipeline(question)

st.set_page_config(page_title='HCMUTE-Chat', layout='wide', page_icon='./resources/images/icon_1.png')

st.image('./resources/images/icon_2.png')
st.title('TRá»¢ LÃ áº¢O Há»– TRá»¢ TUYá»‚N SINH')

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

#Show chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Accept user input
if prompt := st.chat_input("Viáº¿t cÃ¢u há»i cá»§a báº¡n á»Ÿ Ä‘Ã¢y?"):
    #Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    #Show user message in chat message container
    with st.chat_message("user"):
        st.markdown(prompt)

    #Show assistant response in chat message container
    with st.chat_message("assistant"):
        response_container = st.empty()  
        full_response = ""  
        for word in response_generator(prompt):
            full_response += word
            response_container.markdown(full_response)  
        response = full_response.strip()  

    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": response})

with st.expander('LiÃªn há»‡ vá»›i chÃºng tÃ´i'):
    st.markdown("""
    **Hotline tÆ° váº¥n hÆ°á»›ng nghiá»‡p tuyá»ƒn sinh chung:**  
    1. **Tháº§y Nguyá»…n Há»¯u TÃ¹ng** - ChuyÃªn trÃ¡ch tuyá»ƒn sinh - ğŸ“ 0946 939 128  
    2. **Tháº§y Tráº§n Trung Háº­u** - ChuyÃªn trÃ¡ch tuyá»ƒn sinh - ğŸ“ 0983 469 719  
    3. **Tháº§y Äáº·ng Há»¯u Khanh** - PhÃ³ TrÆ°á»Ÿng phÃ²ng Tuyá»ƒn sinh vÃ  CTSV - ğŸ“ 0919 850 721  
    4. **Tháº§y LÃª Quang BÃ¬nh** - PhÃ³ TrÆ°á»Ÿng phÃ²ng Tuyá»ƒn sinh vÃ  CTSV - ğŸ“ 0938 775 001  
    5. **CÃ´ Pháº¡m Thá»‹ Thu SÆ°Æ¡ng** - PhÃ³ TrÆ°á»Ÿng phÃ²ng ÄÃ o táº¡o - ğŸ“ 0933 951 041  
    6. **Tháº§y Tráº§n Thanh ThÆ°á»Ÿng** - TrÆ°á»Ÿng phÃ²ng Tuyá»ƒn sinh vÃ  CTSV - ğŸ“ 0902 043 979  
    7. **Tháº§y VÃµ Viáº¿t CÆ°á»ng** - TrÆ°á»Ÿng phÃ²ng ÄÃ o táº¡o - ğŸ“ 0986 523 475  
      
    ğŸ“Œ **Xem danh sÃ¡ch tÆ° váº¥n viÃªn chuyÃªn sÃ¢u cÃ¡c ngÃ nh Ä‘Ã o táº¡o táº¡i:**  
    ğŸ‘‰ [Äá»™i ngÅ© tÆ° váº¥n cÃ¡c ngÃ nh](https://tinyurl.com/HCMUTE-tuyensinh)
    """, unsafe_allow_html=True)